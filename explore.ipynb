{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m \u001b[39mimport\u001b[39;00m summarize\n\u001b[1;32m      4\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = [word for word in word_tokenize(text.lower()) if word.isalnum()]\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return sentences, ' '.join(words)\n",
    "\n",
    "def generate_summary(text):\n",
    "    sentences, cleaned_text = preprocess_text(text)\n",
    "    summary = summarize(cleaned_text, ratio=0.2)  # Adjust the ratio as needed\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The quick brown fox jumps over the lazy dog.\n",
      "Similarity: -0.0287\n",
      "\n",
      "Text: A stitch in time saves nine.\n",
      "Similarity: -0.0056\n",
      "\n",
      "Text: An apple a day keeps the doctor away.\n",
      "Similarity: 0.0442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"sentence-transformers/distilbert-base-nli-stsb-mean-tokens\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Define your list of texts\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A stitch in time saves nine.\",\n",
    "    \"An apple a day keeps the doctor away.\"\n",
    "]\n",
    "\n",
    "# Encode the texts into embeddings\n",
    "encoded_texts = [tokenizer(text, return_tensors='pt', padding=True, truncation=True) for text in texts]\n",
    "embeddings = [model(**encoded_text).last_hidden_state.mean(dim=1).detach().numpy() for encoded_text in encoded_texts]\n",
    "\n",
    "# Query text\n",
    "query = \"lifestyle\"\n",
    "\n",
    "# Encode the query and calculate similarity scores\n",
    "encoded_query = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "query_embedding = model(**encoded_query).last_hidden_state.mean(dim=1).detach().numpy()\n",
    "similarities = [cosine_similarity(query_embedding, emb)[0][0] for emb in embeddings]\n",
    "\n",
    "# Print results\n",
    "for text, sim in zip(texts, similarities):\n",
    "    print(f\"Text: {text}\\nSimilarity: {sim:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: doc3\n"
     ]
    }
   ],
   "source": [
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "# Define schema for the index\n",
    "schema = Schema(id=ID(unique=True, stored=True), content=TEXT(stored=True))\n",
    "\n",
    "# Create an index or open an existing one\n",
    "index_dir = \"index_dir\"\n",
    "ix = create_in(index_dir, schema)\n",
    "#if not index_dir.exists():\n",
    "#    index_dir.mkdir()\n",
    "#    ix = create_in(index_dir, schema)\n",
    "#else:\n",
    "#ix = open_dir(index_dir)\n",
    "\n",
    "# Create or open an index writer\n",
    "writer = ix.writer()\n",
    "\n",
    "# Add documents to the index\n",
    "documents = [\n",
    "    {\"id\": \"doc1\", \"content\": \"The quick brown fox jumps over the lazy dog.\"},\n",
    "    {\"id\": \"doc2\", \"content\": \"A stitch in time saves nine.\"},\n",
    "    {\"id\": \"doc3\", \"content\": \"An apple a day keeps the doctor away.\"}\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    writer.add_document(**doc)\n",
    "\n",
    "writer.commit()\n",
    "\n",
    "# Perform full-text search\n",
    "search_query = \"doctor\"\n",
    "with ix.searcher() as searcher:\n",
    "    query_parser = QueryParser(\"content\", ix.schema)\n",
    "    query = query_parser.parse(search_query)\n",
    "    results = searcher.search(query)\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Document ID: {result['id']}\")\n",
    "\n",
    "# Clean up resources\n",
    "ix.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Travel from the United States has more than doubled to destinations across the Pacific, including China . London, Paris, Rome and Dublin are the top European destinations for US travelers this summer . Airfare to Europe this summer is averaging nearly $1,200 per ticket, the highest prices in the last six years .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Input text\n",
    "input_text = \"\"\"\n",
    "It’s the summer of international travel for Americans.\n",
    "\n",
    "After three years stuck close to home, people are heading to Europe and the Pacific in droves. And they are spending more money when they get there.\n",
    "\n",
    "\n",
    "The three major US international airlines — American (AAL), Delta (DAL) and United — have all seen a surge in international traffic in recent months and are adding additional service to meet demand.\n",
    "\n",
    "Travelers walk through Denver International Airport on July 30.\n",
    "Travelers walk through Denver International Airport on July 30.\n",
    "Daniel Slim/AFP/Getty Images\n",
    "Travel from the United States has more than doubled to destinations across the Pacific, including China, where travelers faced severe Covid-related restrictions a year ago, airlines reported. Trans-Atlantic demand for flights is also up.\n",
    "\n",
    "And the surge in international travel at those three major carriers all came with no appreciable drop-off in domestic traffic or fares.\n",
    "\n",
    "The top destinations\n",
    "The strong demand is lifting international fares.\n",
    "\n",
    "Airfare to Europe this summer is averaging nearly $1,200 per ticket, the highest prices in the last six years, according to Hopper, a travel booking app. Flights to Europe are costing 12% more than last summer, and 23% more than in summer 2019.\n",
    "\n",
    "Where are people going? London, Paris, Rome and Dublin are the top European destinations for US travelers this summer, according to Hopper.\n",
    "\n",
    "People enjoy the sunset on a bank of the River Seine, in Paris, France, in June.\n",
    "People enjoy the sunset on a bank of the River Seine, in Paris, France, in June.\n",
    "Stephanie Lecocq/Reuters\n",
    "American said passenger revenue on trans-Atlantic route jumped 45% in the first half of this year, and more than tripled on trans-Pacific routes.\n",
    "\n",
    "United said miles traveled by paying passengers jumped 23% on trans-Atlantic routes in the second quarter and 172% on trans-Pacific routes.\n",
    "\n",
    "The gains were even larger at Delta, where trans-Atlantic miles flown by passengers jumped 56% in the first half of the year, and the average amount they paid for each of those miles rose 24%.\n",
    "\n",
    "Overseas travel is also lifting credit-card companies.\n",
    "\n",
    "Spending higher than before Covid\n",
    "At Mastercard, spending linked to overseas travel is currently at 154% of pre-pandemic levels, the company said this week.\n",
    "\n",
    "Mastercard cited “resilient consumer spending, particularly in travel and experiences.”\n",
    "\n",
    "Domestic travelers aren’t seeing the same spike in fares. But the three major carriers’ domestic flights are still packed and most measures of domestic fares are still higher than pre-pandemic levels.\n",
    "\n",
    "CNN’s Chris Isidore contributed to this article.\n",
    "\"\"\"\n",
    "\n",
    "# Generate abstractive summary\n",
    "summary = summarizer(input_text, max_length=100, min_length=20, do_sample=True)[0]['summary_text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Your input text goes here...\"\n",
    "summary = generate_summary(input_text)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
